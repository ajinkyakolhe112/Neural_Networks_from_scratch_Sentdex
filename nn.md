



$$
\begin{align*}
y &= f(X,W)\\
\\
\\
neuron_{single} &=\\ 
z &= X \odot W + b\\
a_{activation} &= \sigma\ (z)\\

layer_{single}\\
X &= a_{activation}

\end{align*}
$$

$Y_{predicted} = f(X_{train\_data},Y_{train\_data})$  
Single Neuron  
Dot Product =  $z = output = X \odot W + b$  
Activation = $a = \sigma\ (z)$  



Parametric Experiment TODO (inspiration: from lecture 5)
- whats mnist accuracy when using step function as activation function?
- step function to sigmoid function. almost same function
- sigmoid function to relu function. 

Current Problems in NN
- No standardization
- No universal best practices for intersection of Programming & Maths. (Maths is executed on Computer by executing our Program)
  - Variable Names, Variable Orientation
- No End to End, Visualized, Intutions Explored, Easy to Understand & Comprehensive not just 1, visualizations, with eucleadian geometry in ipad

If you can run your model in browser & mobile. 